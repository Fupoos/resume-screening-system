"""é‚®ç®±ä»»åŠ¡ - Celeryå¼‚æ­¥ä»»åŠ¡"""
import os
from datetime import datetime
from pathlib import Path
from celery import shared_task
from app.tasks.celery_app import celery_app
from app.services.email_service import EmailService
from app.services.resume_parser import ResumeParser
import logging

logger = logging.getLogger(__name__)

# ç®€å†æ–‡ä»¶ä¿å­˜è·¯å¾„
RESUME_SAVE_PATH = os.getenv('RESUME_SAVE_PATH', '/app/resume_files')


@celery_app.task(name='app.tasks.email_tasks.check_emails')
def check_emails():
    """æ£€æŸ¥æ–°é‚®ä»¶å¹¶å¤„ç†ç®€å†é™„ä»¶"""
    logger.info("å¼€å§‹æ£€æŸ¥é‚®ç®±...")

    # TODO: ä»æ•°æ®åº“è·å–é‚®ç®±é…ç½®
    # ç›®å‰ä½¿ç”¨ç¡¬ç¼–ç çš„é…ç½®ï¼ˆåç»­æ”¹ä¸ºä»æ•°æ®åº“è¯»å–ï¼‰
    email_config = {
        'email_address': os.getenv('DEMO_EMAIL', 'es1@cloudpense.com'),
        'auth_code': os.getenv('DEMO_AUTH_CODE', ''),
        'imap_server': 'imap.exmail.qq.com',
        'imap_port': 993,
        'folder': 'INBOX'
    }

    if not email_config['auth_code']:
        logger.warning("æœªé…ç½®é‚®ç®±æˆæƒç ï¼Œè·³è¿‡é‚®ä»¶æ£€æŸ¥")
        return

    # åˆ›å»ºé‚®ç®±æœåŠ¡
    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port'],
        folder=email_config['folder']
    )

    try:
        # è¿æ¥é‚®ç®±
        if not email_service.connect():
            logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
            return

        # è·å–æœªè¯»é‚®ä»¶
        emails = email_service.fetch_unread_emails(
            filter_keywords=None,  # ä¸è¿‡æ»¤å…³é”®è¯ï¼Œå¤„ç†æ‰€æœ‰å¸¦é™„ä»¶çš„é‚®ä»¶
            sender_whitelist=[]  # å‘ä»¶äººç™½åå•
        )

        logger.info(f"æ‰¾åˆ° {len(emails)} å°ç¬¦åˆæ¡ä»¶çš„æœªè¯»é‚®ä»¶ï¼ˆå·²è¿‡æ»¤ï¼šå¿…é¡»æœ‰PDF/DOCXé™„ä»¶ï¼‰")

        # å¤„ç†æ¯å°é‚®ä»¶
        for idx, email_info in enumerate(emails):
            logger.info(f"å‡†å¤‡å¤„ç†ç¬¬ {idx+1}/{len(emails)} å°é‚®ä»¶: {email_info['subject'][:50]}... (é™„ä»¶æ•°: {len(email_info['attachments'])})")
            process_email.delay(email_info, email_config)

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

    except Exception as e:
        logger.error(f"æ£€æŸ¥é‚®ç®±æ—¶å‡ºé”™: {e}")


@celery_app.task(name='app.tasks.email_tasks.process_email')
def process_email(email_info: dict, email_config: dict):
    """å¤„ç†å•å°é‚®ä»¶"""
    logger.info(f"å¤„ç†é‚®ä»¶: {email_info['subject']}")

    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port']
    )

    if not email_service.connect():
        logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
        return

    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰é™„ä»¶
        has_attachments = False
        for attachment in email_info['attachments']:
            file_name = attachment['filename']

            # åªå¤„ç†ç®€å†æ–‡ä»¶
            if not file_name.endswith(('.pdf', '.PDF', '.docx', '.DOCX', '.doc', '.DOC')):
                continue

            has_attachments = True
            # ä¸‹è½½é™„ä»¶
            file_path = email_service.download_attachment(
                email_info['id'],
                file_name,
                RESUME_SAVE_PATH
            )

            if file_path:
                logger.info(f"é™„ä»¶å·²ä¸‹è½½: {file_path}")
                # è§£æç®€å†
                parse_resume.delay(file_path, email_info)

        # å¦‚æœæ²¡æœ‰é™„ä»¶ä½†æœ‰æ­£æ–‡ï¼Œå°è¯•è§£ææ­£æ–‡
        if not has_attachments and email_info.get('body'):
            logger.info(f"å°è¯•è§£æé‚®ä»¶æ­£æ–‡: {email_info['subject'][:50]}...")
            parse_email_body.delay(email_info, email_config)

        # ç§»åŠ¨é‚®ä»¶åˆ°å·²å¤„ç†æ–‡ä»¶å¤¹
        email_service.move_to_folder(email_info['id'], 'å·²å¤„ç†')

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

    except Exception as e:
        logger.error(f"å¤„ç†é‚®ä»¶æ—¶å‡ºé”™: {e}")


@celery_app.task(name='app.tasks.email_tasks.parse_resume')
def parse_resume(file_path: str, email_info: dict):
    """è§£æç®€å†å¹¶ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¸¦å»é‡æ£€æŸ¥ï¼‰

    æ ¹æ®CLAUDE.mdæ ¸å¿ƒåŸåˆ™ï¼š
    - æ‰€æœ‰è¯„åˆ†é€šè¿‡å¤–éƒ¨Agentå®Œæˆ
    - ä¸ä½¿ç”¨æœ¬åœ°JobMatcherè¿›è¡ŒåŒ¹é…
    - ä¸ä½¿ç”¨æœ¬åœ°ScreeningClassifierè¿›è¡Œåˆ†ç±»
    """
    from app.core.database import SessionLocal
    from app.models.resume import Resume
    from app.services.city_extractor import CityExtractor
    from app.services.job_title_classifier import JobTitleClassifier
    from app.services.agent_client import AgentClient

    logger.info(f"è§£æç®€å†: {file_path}")

    db = SessionLocal()
    try:
        # 0. æ£€æŸ¥ç®€å†æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡file_pathå»é‡ï¼‰
        existing_resume = db.query(Resume).filter(Resume.file_path == file_path).first()
        if existing_resume:
            logger.info(f"ç®€å†å·²å­˜åœ¨ï¼Œè·³è¿‡: {file_path} (ID: {existing_resume.id})")
            return

        # 1. è§£æç®€å†
        parser = ResumeParser()
        email_subject = email_info.get('subject')
        email_body = email_info.get('body', '')
        resume_data = parser.parse_resume(file_path, email_subject=email_subject)

        logger.info(f"ç®€å†è§£æå®Œæˆ: {resume_data.get('candidate_name')}")

        # 2. æå–åŸå¸‚
        city_extractor = CityExtractor()
        city = city_extractor.extract_city(
            email_subject=email_subject,
            email_body=email_body,
            resume_text=resume_data.get('raw_text', '')
        )
        logger.info(f"æå–åŸå¸‚: {city or 'æœªçŸ¥'}")

        # 3. åˆ¤æ–­å…·ä½“èŒä½ï¼ˆä½¿ç”¨å­—ç¬¦ä¸²åŒ¹é…ï¼Œä¸è¯„åˆ†ï¼‰
        job_classifier = JobTitleClassifier()
        job_title = job_classifier.classify_job_title(
            email_subject=email_subject,
            resume_text=resume_data.get('raw_text', ''),
            skills=resume_data.get('skills', []),
            skills_by_level=resume_data.get('skills_by_level', {})
        )
        logger.info(f"åˆ¤æ–­èŒä½: {job_title}")

        # 4. è°ƒç”¨å¤–éƒ¨Agentï¼ˆå”¯ä¸€è¯„åˆ†æ¥æºï¼‰
        agent_client = AgentClient()
        agent_result = agent_client.evaluate_resume(
            job_title=job_title,
            city=city,
            pdf_path=file_path,
            resume_data=resume_data
        )

        # ğŸ”´ æ–°å¢ï¼šå¤„ç†Agentè¿”å›Noneçš„æƒ…å†µï¼ˆæœªé…ç½®FastGPTçš„èŒä½ï¼‰
        if agent_result is None:
            # æœªé…ç½®FastGPTï¼Œä¸è¯„åˆ†
            agent_score = None
            screening_status = 'pending'
            agent_evaluated_at = None
            logger.info(f"èŒä½ '{job_title}' è·³è¿‡Agentè¯„ä¼°ï¼ˆæœªé…ç½®FastGPTï¼‰")
        else:
            # æˆåŠŸè°ƒç”¨FastGPT
            agent_score = agent_result['score']
            screening_status = agent_result.get('screening_status', 'pending')
            agent_evaluated_at = datetime.utcnow()
            logger.info(f"Agentè¯„åˆ†: {agent_score}")

        # 5. ä¿å­˜ç®€å†åˆ°æ•°æ®åº“
        resume = Resume(
            candidate_name=resume_data.get('candidate_name'),
            phone=resume_data.get('phone'),
            email=resume_data.get('email'),
            education=resume_data.get('education'),
            education_level=resume_data.get('education_level'),
            work_years=resume_data.get('work_years', 0),
            skills=resume_data.get('skills', []),
            skills_by_level=resume_data.get('skills_by_level', {}),
            work_experience=resume_data.get('work_experience', []),
            project_experience=resume_data.get('project_experience', []),
            education_history=resume_data.get('education_history', []),
            raw_text=resume_data.get('raw_text'),
            file_path=file_path,
            file_type=file_path.split('.')[-1] if '.' in file_path else None,
            source_email_id=email_info.get('id'),
            source_email_subject=email_info.get('subject'),
            source_sender=email_info.get('sender'),
            city=city,
            job_category=job_title,
            pdf_path=file_path,
            agent_score=agent_score,
            agent_evaluation_id=agent_result.get('evaluation_id') if agent_result else None,
            agent_evaluated_at=agent_evaluated_at,
            screening_status=screening_status,
            status='processed'
        )
        db.add(resume)
        db.commit()
        db.refresh(resume)

        logger.info(f"ç®€å†å·²ä¿å­˜åˆ°æ•°æ®åº“: {resume.id}")

        # âŒ å·²åˆ é™¤æœ¬åœ°JobMatcherè‡ªåŠ¨åŒ¹é…ï¼ˆè¿åæ ¸å¿ƒåŸåˆ™ï¼‰

        logger.info(f"ç®€å†å¤„ç†å®Œæˆ: {resume.candidate_name}, Agentè¯„åˆ†: {agent_result['score']}")

    except Exception as e:
        db.rollback()
        logger.error(f"å¤„ç†ç®€å†æ—¶å‡ºé”™: {e}")
        raise
    finally:
        db.close()


@celery_app.task(name='app.tasks.email_tasks.fetch_recent_resumes')
def fetch_recent_resumes(limit: int = 20):
    """æŠ“å–æœ€è¿‘Nå°é‚®ä»¶ä¸­çš„ç®€å†é™„ä»¶ï¼ˆä»è¿‘åˆ°è¿œï¼Œæ‰«ææ‰€æœ‰æ–‡ä»¶å¤¹ï¼‰

    Args:
        limit: æŠ“å–é‚®ä»¶æ•°é‡ï¼ˆé»˜è®¤20å°ï¼‰
    """
    logger.info(f"å¼€å§‹æŠ“å–æœ€è¿‘ {limit} å°é‚®ä»¶ä¸­çš„ç®€å†...")

    email_config = {
        'email_address': os.getenv('DEMO_EMAIL', 'es1@cloudpense.com'),
        'auth_code': os.getenv('DEMO_AUTH_CODE', ''),
        'imap_server': 'imap.exmail.qq.com',
        'imap_port': 993,
        'folder': 'INBOX'
    }

    if not email_config['auth_code']:
        logger.warning("æœªé…ç½®é‚®ç®±æˆæƒç ï¼Œè·³è¿‡")
        return {'status': 'error', 'message': 'æœªé…ç½®é‚®ç®±æˆæƒç '}

    # åˆ›å»ºé‚®ç®±æœåŠ¡
    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port'],
        folder=email_config['folder']
    )

    try:
        # è¿æ¥é‚®ç®±
        if not email_service.connect():
            logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
            return {'status': 'error', 'message': 'è¿æ¥é‚®ç®±å¤±è´¥'}

        # è·å–æ‰€æœ‰æ–‡ä»¶å¤¹åˆ—è¡¨
        try:
            status, folders = email_service.client.list()
            logger.info(f"IMAP list() status: {status}, è¿”å›æ•°æ®ç±»å‹: {type(folders)}, æ•°é‡: {len(folders) if folders else 0}")

            # å¯¼å…¥ IMAP UTF-7 è§£ç å™¨
            from imapclient.imap_utf7 import decode

            # å­˜å‚¨æ–‡ä»¶å¤¹ä¿¡æ¯ï¼š{decoded_name: encoded_name}
            folder_map = {}
            for line in folders:
                # line æ ¼å¼: b'(\\HasNoChildren) "/" "folder_name"'
                if isinstance(line, bytes):
                    line_str = line.decode('latin-1')
                else:
                    line_str = str(line)

                # æå–æ–‡ä»¶å¤¹åï¼ˆåœ¨æœ€åä¸€ä¸ªå¼•å·ä¸­ï¼‰
                import re
                match = re.search(r'"([^"]+)"\s*$', line_str)
                if match:
                    folder_encoded = match.group(1)
                    # è§£ç  IMAP UTF-7 (ä½¿ç”¨ imapclient çš„ decode å‡½æ•°ï¼Œéœ€è¦ bytes è¾“å…¥)
                    try:
                        folder_name_decoded = decode(folder_encoded.encode('latin-1'))
                    except:
                        folder_name_decoded = folder_encoded
                    logger.info(f"è§£ææ–‡ä»¶å¤¹: {folder_encoded} -> {folder_name_decoded}")

                    # å­˜å‚¨æ˜ å°„ï¼šdecoded -> encoded
                    folder_map[folder_name_decoded] = folder_encoded

            # è·å–æ‰€æœ‰å·²è§£ç çš„æ–‡ä»¶å¤¹ååˆ—è¡¨
            folder_names = list(folder_map.keys())
            logger.info(f"æ‰¾åˆ°æ–‡ä»¶å¤¹: {folder_names}")

            # ä¼˜å…ˆæ‰«æåŒ…å«"å·²å¤„ç†"/"processed"/"Processed"çš„æ–‡ä»¶å¤¹
            folders_to_scan = []  # List of decoded names
            processed_folder = None

            # å…ˆæ‰¾"å·²å¤„ç†"æ–‡ä»¶å¤¹
            for fn in folder_names:
                if 'å·²å¤„ç†' in fn or 'processed' in fn.lower() or 'Processed' in fn:
                    processed_folder = fn
                    folders_to_scan.insert(0, fn)  # ä¼˜å…ˆå¤„ç†
                    break

            # å†æ‰¾INBOX
            for fn in folder_names:
                if 'INBOX' in fn.upper() and fn != processed_folder:
                    folders_to_scan.append(fn)
                    break

            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œæ·»åŠ å…¶ä»–æ–‡ä»¶å¤¹
            for fn in folder_names:
                if fn not in folders_to_scan and fn != processed_folder:
                    folders_to_scan.append(fn)
                    if len(folders_to_scan) >= 3:  # æœ€å¤šæ‰«æ3ä¸ªæ–‡ä»¶å¤¹
                        break

            logger.info(f"å°†æ‰«ææ–‡ä»¶å¤¹: {folders_to_scan}")

        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤¹åˆ—è¡¨å¤±è´¥: {e}")
            folder_map = {'INBOX': 'INBOX'}  # Fallback mapping
            folders_to_scan = ['INBOX']

        all_emails = []
        total_found = 0

        for folder_decoded in folders_to_scan:
            logger.info(f"æ‰«ææ–‡ä»¶å¤¹: {folder_decoded}")

            # è·å–ç¼–ç åçš„æ–‡ä»¶å¤¹åï¼ˆç”¨äº IMAP æ“ä½œï¼‰
            folder_encoded = folder_map.get(folder_decoded, folder_decoded)

            # åˆ‡æ¢åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
            try:
                # ä½¿ç”¨ IMAP UTF-7 ç¼–ç çš„æ–‡ä»¶å¤¹å
                email_service.client.select(folder_encoded)
            except Exception as e:
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•å¼•ç”¨çš„æ–¹å¼
                try:
                    email_service.client.select('"{}"'.format(folder_encoded))
                except Exception as e2:
                    logger.warning(f"æ— æ³•åˆ‡æ¢åˆ°æ–‡ä»¶å¤¹ {folder_decoded} (encoded: {folder_encoded}): {e2}")
                    continue

            # è·å–è¯¥æ–‡ä»¶å¤¹çš„é‚®ä»¶
            fetch_limit = limit if limit < 1000 else 9999  # å¦‚æœlimit>=1000ï¼Œè¡¨ç¤ºè·å–å…¨éƒ¨
            emails = email_service.fetch_recent_emails(
                limit=fetch_limit,
                filter_keywords=None,
                sender_whitelist=[]
            )

            logger.info(f"æ–‡ä»¶å¤¹ {folder_decoded} ä¸­æ‰¾åˆ° {len(emails)} å°ç¬¦åˆæ¡ä»¶çš„é‚®ä»¶")
            all_emails.extend(emails)
            total_found += len(emails)

            # å¦‚æœå·²ç»æ‰¾åˆ°è¶³å¤Ÿçš„é‚®ä»¶ä¸”ä¸æ˜¯è·å–å…¨éƒ¨æ¨¡å¼ï¼Œåœæ­¢æ‰«æ
            if fetch_limit < 1000 and len(all_emails) >= fetch_limit:
                logger.info(f"å·²æ‰¾åˆ° {len(all_emails)} å°é‚®ä»¶ï¼Œè¾¾åˆ°ç›®æ ‡æ•°é‡")
                break

        # å»é‡ï¼šé€šè¿‡é‚®ä»¶ID
        seen_ids = set()
        unique_emails = []
        for email in all_emails:
            if email['id'] not in seen_ids:
                seen_ids.add(email['id'])
                unique_emails.append(email)

        logger.info(f"æ€»å…±æ‰¾åˆ° {len(unique_emails)} å°å”¯ä¸€é‚®ä»¶ï¼ˆå»é‡åï¼‰")

        # å¤„ç†æ¯å°é‚®ä»¶ï¼ˆé™åˆ¶æ•°é‡ï¼‰
        processed_count = 0
        for idx, email_info in enumerate(unique_emails[:limit]):
            logger.info(
                f"å‡†å¤‡å¤„ç†ç¬¬ {idx+1}/{min(len(unique_emails), limit)} å°é‚®ä»¶: "
                f"{email_info['subject'][:50]}... (é™„ä»¶æ•°: {len(email_info['attachments'])})"
            )
            process_email.delay(email_info, email_config)
            processed_count += 1

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

        result = {
            'status': 'success',
            'message': f'ä» {len(folders_to_scan)} ä¸ªæ–‡ä»¶å¤¹ä¸­æ‰¾åˆ° {total_found} å°é‚®ä»¶ï¼Œå¤„ç†äº† {processed_count} å°',
            'folders_scanned': folders_to_scan,
            'total_emails_found': total_found,
            'processed': processed_count
        }

        logger.info(f"æŠ“å–å®Œæˆ: {result}")
        return result

    except Exception as e:
        logger.error(f"æŠ“å–é‚®ä»¶æ—¶å‡ºé”™: {e}")
        return {'status': 'error', 'message': f'æŠ“å–å¤±è´¥: {str(e)}'}


@celery_app.task(name='app.tasks.email_tasks.check_new_emails')
def check_new_emails():
    """æ£€æŸ¥æ–°çš„æœªè¯»é‚®ä»¶ï¼ˆç”¨äºå®šæ—¶è‡ªåŠ¨æŠ“å–ï¼‰"""
    logger.info("å¼€å§‹æ£€æŸ¥æ–°é‚®ä»¶...")

    email_config = {
        'email_address': os.getenv('DEMO_EMAIL', 'es1@cloudpense.com'),
        'auth_code': os.getenv('DEMO_AUTH_CODE', ''),
        'imap_server': 'imap.exmail.qq.com',
        'imap_port': 993,
        'folder': 'INBOX'
    }

    if not email_config['auth_code']:
        logger.warning("æœªé…ç½®é‚®ç®±æˆæƒç ï¼Œè·³è¿‡")
        return {'status': 'error', 'message': 'æœªé…ç½®é‚®ç®±æˆæƒç '}

    # åˆ›å»ºé‚®ç®±æœåŠ¡
    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port'],
        folder=email_config['folder']
    )

    try:
        # è¿æ¥é‚®ç®±
        if not email_service.connect():
            logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
            return {'status': 'error', 'message': 'è¿æ¥é‚®ç®±å¤±è´¥'}

        # åªè·å–æœªè¯»é‚®ä»¶
        emails = email_service.fetch_unread_emails(
            filter_keywords=None,
            sender_whitelist=[]
        )

        logger.info(f"æ‰¾åˆ° {len(emails)} å°æœªè¯»é‚®ä»¶ï¼ˆæœ‰PDF/DOCXé™„ä»¶ï¼‰")

        if len(emails) == 0:
            logger.info("æ²¡æœ‰æ–°çš„æœªè¯»é‚®ä»¶éœ€è¦å¤„ç†")
            email_service.disconnect()
            return {
                'status': 'success',
                'message': 'æ²¡æœ‰æ–°é‚®ä»¶',
                'total_emails': 0,
                'processed': 0
            }

        # å¤„ç†æ¯å°é‚®ä»¶
        for idx, email_info in enumerate(emails):
            logger.info(
                f"å‡†å¤‡å¤„ç†ç¬¬ {idx+1}/{len(emails)} å°æ–°é‚®ä»¶: "
                f"{email_info['subject'][:50]}... (é™„ä»¶æ•°: {len(email_info['attachments'])})"
            )
            process_email.delay(email_info, email_config)

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

        result = {
            'status': 'success',
            'message': f'æˆåŠŸå¤„ç† {len(emails)} å°æ–°é‚®ä»¶',
            'total_emails': len(emails),
            'processed': len(emails)
        }

        logger.info(f"æ£€æŸ¥å®Œæˆ: {result}")
        return result

    except Exception as e:
        logger.error(f"æ£€æŸ¥æ–°é‚®ä»¶æ—¶å‡ºé”™: {e}")
        return {'status': 'error', 'message': f'æ£€æŸ¥å¤±è´¥: {str(e)}'}


@celery_app.task(name='app.tasks.email_tasks.parse_email_body')
def parse_email_body(email_info: dict, email_config: dict):
    """è§£æé‚®ä»¶æ­£æ–‡å¹¶æå–å€™é€‰äººä¿¡æ¯

    æ ¹æ®CLAUDE.mdæ ¸å¿ƒåŸåˆ™ï¼š
    - æ‰€æœ‰è¯„åˆ†é€šè¿‡å¤–éƒ¨Agentå®Œæˆ
    - ä¸ä½¿ç”¨æœ¬åœ°JobMatcherè¿›è¡ŒåŒ¹é…
    """
    from app.core.database import SessionLocal
    from app.models.resume import Resume
    import re

    logger.info(f"è§£æé‚®ä»¶æ­£æ–‡: {email_info['subject']}")

    db = SessionLocal()
    try:
        # ä½¿ç”¨é‚®ä»¶IDä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼ˆå»é‡ï¼‰
        unique_id = f"email_{email_info['id']}"
        existing_resume = db.query(Resume).filter(Resume.file_path == unique_id).first()
        if existing_resume:
            logger.info(f"é‚®ä»¶æ­£æ–‡å·²å¤„ç†è¿‡ï¼Œè·³è¿‡: {email_info['id']}")
            return

        # æå–æ­£æ–‡ä¸­çš„å€™é€‰äººä¿¡æ¯
        body = email_info.get('body', '')
        subject = email_info.get('subject', '')

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å€™é€‰äººå§“å
        candidate_name = None

        # æ ¼å¼1: BOSSç›´è˜ - "å§“å | Xå¹´ï¼Œåº”è˜ å²—ä½"
        name_match = re.search(r'^([\u4e00-\u9fa5]{2,4})\s*\|', subject)
        if name_match:
            candidate_name = name_match.group(1)
        else:
            # æ ¼å¼2: å®ä¹ åƒ§ç½‘ - "å²—ä½-å§“å-å­¦æ ¡"
            name_match2 = re.search(r'-([\u4e00-\u9fa5]{2,4})-', subject)
            if name_match2:
                candidate_name = name_match2.group(1)
            else:
                # æ ¼å¼3: é±¼æ³¡ç›´è˜ - "å§“å|åº”è˜å²—ä½"
                name_match3 = re.search(r'^([\u4e00-\u9fa5]{2,4})\|', subject)
                if name_match3:
                    candidate_name = name_match3.group(1)
                else:
                    # æ ¼å¼4: åœ¨æ­£æ–‡ä¸­æŸ¥æ‰¾ "å§“å |"
                    name_match4 = re.search(r'([\u4e00-\u9fa5]{2,4})\s*\|', body[:500])
                    if name_match4:
                        # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„å…³é”®è¯
                        name = name_match4.group(1)
                        if name not in ['é”€å”®æ€»ç›‘', 'é›¶å”®è¡Œä¸š', 'å‚ç›´å¹³å°', 'è´¢åŠ¡å®æ–½', 'å¸‚åœºè¿è¥', 'é”€å”®ä»£è¡¨']:
                            candidate_name = name

        # æå–æ‰‹æœºå·ï¼ˆä¼˜å…ˆåœ¨æ­£æ–‡æ‰¾ï¼‰
        phone_match = re.search(r'1[3-9]\d{9}', body)
        phone = phone_match.group(0) if phone_match else None

        # æå–é‚®ç®±
        email_match = re.search(r'[\w\.-]+@[\w\.-]+\.\w+', body)
        email_addr = email_match.group(0) if email_match else None

        # æå–å·¥ä½œç»éªŒï¼ˆä¾‹å¦‚ï¼š"1å¹´"ï¼Œ"2å¹´ä»¥ä¸Š"ï¼Œ"25å¹´åº”å±Šç”Ÿ"ï¼‰
        experience_match = re.search(r'(\d+)\s*å¹´', subject)
        if experience_match:
            work_years = int(experience_match.group(1))
        else:
            experience_match2 = re.search(r'(\d+)\s*å¹´', body)
            work_years = int(experience_match2.group(1)) if experience_match2 else 0

        # å¦‚æœæ˜¯åº”å±Šç”Ÿï¼Œå·¥ä½œç»éªŒè®¾ä¸º0
        if 'åº”å±Š' in subject or 'åº”å±Š' in body:
            work_years = 0

        # æå–åº”è˜å²—ä½
        job_match = re.search(r'åº”è˜\s*([^\s|ã€]+)', subject)
        target_position = job_match.group(1) if job_match else None

        logger.info(f"æå–å€™é€‰äººä¿¡æ¯: å§“å={candidate_name}, æ‰‹æœº={phone}, é‚®ç®±={email_addr}, å·¥ä½œç»éªŒ={work_years}å¹´")

        # æå–æŠ€èƒ½ï¼ˆä½¿ç”¨ResumeParserï¼‰
        from app.services.resume_parser import ResumeParser
        parser = ResumeParser()
        email_body_full = body[:10000]  # ä½¿ç”¨å‰10000å­—ç¬¦æå–æŠ€èƒ½
        extracted_skills = parser._extract_skills(email_body_full)

        logger.info(f"ä»é‚®ä»¶æ­£æ–‡æå–åˆ° {len(extracted_skills)} ä¸ªæŠ€èƒ½: {extracted_skills[:10]}")

        # æå–åŸå¸‚ï¼ˆæ–°å¢ï¼‰
        city_extractor = CityExtractor()
        city = city_extractor.extract_city(
            email_subject=subject,
            email_body=body,
            resume_text=body[:5000]
        )
        logger.info(f"æå–åŸå¸‚: {city or 'æœªçŸ¥'}")

        # åˆ¤æ–­å…·ä½“èŒä½ï¼ˆæ–°å¢ï¼‰
        job_classifier = JobTitleClassifier()
        job_title = job_classifier.classify_job_title(
            email_subject=subject,
            resume_text=body[:5000],
            skills=extracted_skills,
            skills_by_level={}
        )
        logger.info(f"åˆ¤æ–­èŒä½: {job_title}")

        # è°ƒç”¨å¤–éƒ¨Agentï¼ˆå”¯ä¸€è¯„åˆ†æ¥æºï¼‰
        # æ³¨æ„ï¼šé‚®ä»¶æ­£æ–‡æ²¡æœ‰PDFæ–‡ä»¶ï¼Œæ‰€ä»¥ä¼ é€’ç©ºè·¯å¾„
        resume_data = {
            'candidate_name': candidate_name,
            'phone': phone,
            'email': email_addr,
            'skills': extracted_skills,
            'raw_text': body[:5000]
        }
        agent_client = AgentClient()
        agent_result = agent_client.evaluate_resume(
            job_title=job_title,
            city=city,
            pdf_path='',  # é‚®ä»¶æ­£æ–‡æ— PDF
            resume_data=resume_data
        )

        # ğŸ”´ æ–°å¢ï¼šå¤„ç†Agentè¿”å›Noneçš„æƒ…å†µï¼ˆæœªé…ç½®FastGPTçš„èŒä½ï¼‰
        if agent_result is None:
            # æœªé…ç½®FastGPTï¼Œä¸è¯„åˆ†
            agent_score = None
            screening_status = 'pending'
            agent_evaluated_at = None
            logger.info(f"èŒä½ '{job_title}' è·³è¿‡Agentè¯„ä¼°ï¼ˆæœªé…ç½®FastGPTï¼‰")
        else:
            # æˆåŠŸè°ƒç”¨FastGPT
            agent_score = agent_result['score']
            screening_status = agent_result.get('screening_status', 'pending')
            agent_evaluated_at = datetime.utcnow()
            logger.info(f"Agentè¯„åˆ†: {agent_score}")

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä¿®æ”¹ï¼‰
        resume = Resume(
            candidate_name=candidate_name or "æœªçŸ¥å€™é€‰äºº",
            phone=phone,
            email=email_addr,
            education=None,
            education_level=None,
            work_years=work_years,
            skills=extracted_skills,  # ä½¿ç”¨æå–çš„æŠ€èƒ½
            skills_by_level={},
            work_experience=[],
            project_experience=[],
            education_history=[],
            raw_text=body[:5000],  # ä¿å­˜å‰5000ä¸ªå­—ç¬¦
            file_path=unique_id,
            file_type='email_body',
            source_email_id=email_info.get('id'),
            source_email_subject=email_info.get('subject'),
            source_sender=email_info.get('sender'),
            # æ–°å¢å­—æ®µ
            city=city,
            job_category=job_title,
            pdf_path='',  # é‚®ä»¶æ­£æ–‡æ— PDF
            agent_score=agent_score,
            agent_evaluation_id=agent_result.get('evaluation_id') if agent_result else None,
            agent_evaluated_at=datetime.utcnow(),
            screening_status=screening_status,
            status='processed'
        )
        db.add(resume)
        db.commit()
        db.refresh(resume)

        logger.info(f"é‚®ä»¶æ­£æ–‡å·²ä¿å­˜åˆ°æ•°æ®åº“: {resume.id}")

        # âŒ å·²åˆ é™¤æœ¬åœ°JobMatcherè‡ªåŠ¨åŒ¹é…ï¼ˆè¿åæ ¸å¿ƒåŸåˆ™ï¼‰

        logger.info(f"é‚®ä»¶æ­£æ–‡å¤„ç†å®Œæˆ: {resume.candidate_name}, Agentè¯„åˆ†: {agent_result['score']}")

    except Exception as e:
        db.rollback()
        logger.error(f"è§£æé‚®ä»¶æ­£æ–‡æ—¶å‡ºé”™: {e}")
        raise
    finally:
        db.close()
