"""é‚®ç®±ä»»åŠ¡ - Celeryå¼‚æ­¥ä»»åŠ¡"""
import os
from datetime import datetime
from pathlib import Path
from celery import shared_task
from app.tasks.celery_app import celery_app
from app.services.email_service import EmailService
from app.services.resume_parser import ResumeParser
import logging

logger = logging.getLogger(__name__)

# ç®€å†æ–‡ä»¶ä¿å­˜è·¯å¾„
RESUME_SAVE_PATH = os.getenv('RESUME_SAVE_PATH', '/app/resume_files')


@celery_app.task(name='app.tasks.email_tasks.check_emails')
def check_emails():
    """æ£€æŸ¥æ–°é‚®ä»¶å¹¶å¤„ç†ç®€å†é™„ä»¶"""
    logger.info("å¼€å§‹æ£€æŸ¥é‚®ç®±...")

    # TODO: ä»æ•°æ®åº“è·å–é‚®ç®±é…ç½®
    # ç›®å‰ä½¿ç”¨ç¡¬ç¼–ç çš„é…ç½®ï¼ˆåç»­æ”¹ä¸ºä»æ•°æ®åº“è¯»å–ï¼‰
    email_config = {
        'email_address': os.getenv('DEMO_EMAIL', 'es1@cloudpense.com'),
        'auth_code': os.getenv('DEMO_AUTH_CODE', ''),
        'imap_server': 'imap.exmail.qq.com',
        'imap_port': 993,
        'folder': 'INBOX'
    }

    if not email_config['auth_code']:
        logger.warning("æœªé…ç½®é‚®ç®±æˆæƒç ï¼Œè·³è¿‡é‚®ä»¶æ£€æŸ¥")
        return

    # åˆ›å»ºé‚®ç®±æœåŠ¡
    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port'],
        folder=email_config['folder']
    )

    try:
        # è¿æ¥é‚®ç®±
        if not email_service.connect():
            logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
            return

        # è·å–æœªè¯»é‚®ä»¶ï¼ˆä¸å†è¿‡æ»¤ï¼‰
        emails = email_service.fetch_unread_emails(
            save_path=RESUME_SAVE_PATH  # ç›´æ¥ä¿å­˜é™„ä»¶
        )


        logger.info(f"æ‰¾åˆ° {len(emails)} å°æœªè¯»é‚®ä»¶")

        # å¤„ç†æ¯å°é‚®ä»¶
        for idx, email_info in enumerate(emails):
            logger.info(f"å‡†å¤‡å¤„ç†ç¬¬ {idx+1}/{len(emails)} å°é‚®ä»¶: {email_info['subject'][:50]}... (é™„ä»¶æ•°: {len(email_info['attachments'])})")
            celery_app.send_task('app.tasks.email_tasks.process_email', args=[email_info, email_config])

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

    except Exception as e:
        logger.error(f"æ£€æŸ¥é‚®ç®±æ—¶å‡ºé”™: {e}")


@celery_app.task(name='app.tasks.email_tasks.process_email')
def process_email(email_info: dict, email_config: dict):
    """å¤„ç†å•å°é‚®ä»¶"""
    logger.info(f"å¤„ç†é‚®ä»¶: {email_info['subject']}")

    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port']
    )

    if not email_service.connect():
        logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
        return

    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰é™„ä»¶
        has_attachments = False
        for attachment in email_info['attachments']:
            file_name = attachment['filename']

            # åªå¤„ç†ç®€å†æ–‡ä»¶
            if not file_name.endswith(('.pdf', '.PDF', '.docx', '.DOCX', '.doc', '.DOC')):
                continue

            has_attachments = True

            # ä¼˜å…ˆä½¿ç”¨å·²ä¿å­˜çš„è·¯å¾„ï¼ˆåœ¨fetchæ—¶å·²ä¿å­˜ï¼‰
            file_path = attachment.get('saved_path')

            # å¦‚æœæ²¡æœ‰ä¿å­˜è·¯å¾„ï¼Œå°è¯•é‡æ–°ä¸‹è½½
            if not file_path:
                file_path = email_service.download_attachment(
                    email_info['id'],
                    file_name,
                    RESUME_SAVE_PATH
                )

            if file_path:
                logger.info(f"ä½¿ç”¨é™„ä»¶æ–‡ä»¶: {file_path}")
                # è§£æç®€å†ï¼ˆä½¿ç”¨send_taskç¡®ä¿ä»»åŠ¡è¢«æ­£ç¡®å‘é€ï¼‰
                celery_app.send_task('app.tasks.email_tasks.parse_resume', args=[file_path, email_info])
                logger.info(f"å·²è§¦å‘è§£æä»»åŠ¡: {file_path}")

        # æ²¡æœ‰PDFé™„ä»¶çš„é‚®ä»¶è·³è¿‡å¤„ç†ï¼ˆç¬¦åˆCLAUDE.mdåŸåˆ™2ï¼šåªä¿ç•™æœ‰PDF+æ­£æ–‡çš„ç®€å†ï¼‰
        if not has_attachments:
            logger.info(f"é‚®ä»¶æ— PDFé™„ä»¶ï¼Œè·³è¿‡å¤„ç†: {email_info['subject'][:50]}...")

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

        # æ›´æ–°è¿›åº¦ï¼ˆé‚®ä»¶å¤„ç†å®Œæˆï¼Œæ— è®ºæ˜¯å¦æœ‰é™„ä»¶ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œç»Ÿä¸€è®¡æ•°ï¼Œparse_resumeä¸­ä¸å†è®¡æ•°ï¼Œé¿å…é‡å¤
        try:
            from app.api.v1.email_monitoring import increment_import_success
            increment_import_success()
        except Exception as status_err:
            logger.warning(f"æ›´æ–°çŠ¶æ€å¤±è´¥: {status_err}")

    except Exception as e:
        logger.error(f"å¤„ç†é‚®ä»¶æ—¶å‡ºé”™: {e}")


@celery_app.task(name='app.tasks.email_tasks.parse_resume')
def parse_resume(file_path: str, email_info: dict):
    """è§£æç®€å†å¹¶ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¸¦å»é‡æ£€æŸ¥ï¼‰

    æ ¹æ®CLAUDE.mdæ ¸å¿ƒåŸåˆ™ï¼š
    - æ‰€æœ‰è¯„åˆ†é€šè¿‡å¤–éƒ¨Agentå®Œæˆ
    - ä¸ä½¿ç”¨æœ¬åœ°JobMatcherè¿›è¡ŒåŒ¹é…
    - ä¸ä½¿ç”¨æœ¬åœ°ScreeningClassifierè¿›è¡Œåˆ†ç±»
    """
    from app.core.database import SessionLocal
    from app.models.resume import Resume
    from app.services.city_extractor import CityExtractor
    from app.services.job_title_classifier import JobTitleClassifier
    from app.services.agent_client import AgentClient

    logger.info(f"è§£æç®€å†: {file_path}")

    db = SessionLocal()
    try:

        # 1. è§£æç®€å†ï¼ˆå…ˆè§£ææ‰èƒ½è·å–å§“åå’Œæ‰‹æœºå·ç”¨äºå»é‡ï¼‰
        parser = ResumeParser()
        email_subject = email_info.get('subject')
        email_body = email_info.get('body', '')
        resume_data = parser.parse_resume(file_path, email_subject=email_subject)

        # ğŸ”´ æ–°å¢ï¼šå¤„ç†æ— æ­£æ–‡å†…å®¹çš„ç®€å†ï¼ˆä¿å­˜ä¸ºéœ€è¦äººå·¥å®¡æ ¸ï¼‰
        needs_manual_review = False
        if not resume_data.get('raw_text'):
            logger.warning(f"ç®€å†æ— æ­£æ–‡å†…å®¹ï¿½ï¿½å°†æ ‡è®°ä¸ºéœ€è¦äººå·¥å®¡æ ¸: {file_path}")
            needs_manual_review = True
            # å°è¯•ä»æ–‡ä»¶åæˆ–é‚®ä»¶ä¸»é¢˜æå–å€™é€‰äººå§“å
            candidate_name = resume_data.get('candidate_name')
            if not candidate_name:
                # ä»æ–‡ä»¶åæå–å§“å
                import os
                import re
                filename = os.path.basename(file_path)
                # å°è¯•ä»æ–‡ä»¶åä¸­æå–ä¸­æ–‡å§“å
                name_match = re.search(r'([\u4e00-\u9fa5]{2,4})', filename)
                if name_match:
                    candidate_name = name_match.group(1)
                else:
                    candidate_name = "å¾…è¡¥å……ï¿½ï¿½å"

            # è®¾ç½®é»˜è®¤å€¼
            resume_data['raw_text'] = ""  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ— æ­£æ–‡
            resume_data['skills'] = []
            resume_data['education'] = None
            resume_data['work_years'] = 0
            resume_data['phone'] = None
            resume_data['email'] = None

        logger.info(f"ç®€å†è§£æå®Œæˆ: {resume_data.get('candidate_name')}")

        # 3. åˆ¤æ–­å…·ä½“èŒä½ï¼ˆä½¿ç”¨å­—ç¬¦ä¸²åŒ¹é…ï¼Œä¸è¯„åˆ†ï¼‰
        # æå–åŸå¸‚ï¼ˆç»Ÿä¸€å¤„ç†ï¼Œåç»­å¯ç”¨ï¼‰
        city_extractor = CityExtractor()
        city_result = city_extractor.extract_city(
            email_subject=email_subject,
            email_body=email_body,
            resume_text=resume_data.get('raw_text', '')
        )
        city = city_result.confirmed_city
        candidate_cities = city_result.candidate_cities
        logger.info(f"æå–åŸå¸‚ - ç¡®è®¤: {city or 'æ— '}, å€™é€‰: {candidate_cities or 'æ— '}")

        job_title = None
        if not needs_manual_review:
            job_classifier = JobTitleClassifier()
            job_title = job_classifier.classify_job_title(
                email_subject=email_subject,
                resume_text=resume_data.get('raw_text', ''),
                skills=resume_data.get('skills', []),
                skills_by_level=resume_data.get('skills_by_level', {})
            )
            logger.info(f"åˆ¤æ–­èŒä½: {job_title}")

        # 4. è°ƒç”¨å¤–éƒ¨Agentï¼ˆå”¯ä¸€è¯„åˆ†æ¥æºï¼‰- æ— æ­£æ–‡çš„ç®€å†è·³è¿‡
        if needs_manual_review:
            # æ— æ­£æ–‡å†…å®¹ï¼Œè·³è¿‡Agentè¯„ä¼°ï¼Œæ ‡è®°ä¸ºéœ€è¦äººå·¥å®¡æ ¸
            agent_score = None
            screening_status = 'needs_review'  # éœ€è¦äººå·¥å®¡æ ¸
            agent_evaluated_at = None
            agent_result = None
            job_title = None
            logger.info(f"ç®€å†æ— æ­£æ–‡ï¼Œè·³è¿‡Agentè¯„ä¼°ï¼Œæ ‡è®°ä¸ºéœ€è¦äººå·¥å®¡æ ¸")
        else:
            # æœ‰æ­£æ–‡å†…å®¹ï¼Œæ­£å¸¸è°ƒç”¨Agentè¯„ä¼°
            job_classifier = JobTitleClassifier()
            job_title = job_classifier.classify_job_title(
                email_subject=email_subject,
                resume_text=resume_data.get('raw_text', ''),
                skills=resume_data.get('skills', []),
                skills_by_level=resume_data.get('skills_by_level', {})
            )
            logger.info(f"åˆ¤æ–­èŒä½: {job_title}")

            agent_client = AgentClient()
            agent_result = agent_client.evaluate_resume(
                job_title=job_title,
                city=city,
                pdf_path=file_path,
                resume_data=resume_data
            )

        # ğŸ”´ æ–°å¢ï¼šå¤„ç†Agentè¿”å›Noneçš„æƒ…å†µï¼ˆæœªé…ç½®FastGPTçš„èŒä½ï¼‰
        if agent_result is None:
            # æœªé…ç½®FastGPTï¼Œä¸è¯„åˆ†
            agent_score = None
            screening_status = 'pending'
            agent_evaluated_at = None
            logger.info(f"èŒä½ '{job_title}' è·³è¿‡Agentè¯„ä¼°ï¼ˆæœªé…ç½®FastGPTï¼‰")
        else:
            # æˆåŠŸè°ƒç”¨FastGPT
            agent_score = agent_result['score']
            screening_status = agent_result.get('screening_status', 'pending')
            agent_evaluated_at = datetime.utcnow()
            logger.info(f"Agentè¯„åˆ†: {agent_score}")

        # 5. æ£€æŸ¥ç®€å†æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºå§“å+æ‰‹æœºå·å»é‡ï¼‰
        candidate_name = resume_data.get('candidate_name')
        phone = resume_data.get('phone')

        existing_resume = None
        if candidate_name and phone:
            # ä¼˜å…ˆä½¿ç”¨å§“å+æ‰‹æœºå·å»é‡
            existing_resume = db.query(Resume).filter(
                Resume.candidate_name == candidate_name,
                Resume.phone == phone
            ).first()
        elif candidate_name:
            # å¦‚æœæ²¡æœ‰æ‰‹æœºå·ï¼Œä»…ä½¿ç”¨å§“åå»é‡
            existing_resume = db.query(Resume).filter(
                Resume.candidate_name == candidate_name
            ).first()

        if existing_resume:
            # æ›´æ–°ç°æœ‰ç®€å†è®°å½•
            logger.info(f"ç®€å†å·²å­˜åœ¨ï¼ˆå§“å: {candidate_name}, æ‰‹æœº: {phone}ï¼‰ï¼Œæ›´æ–°è®°å½•: {existing_resume.id}")
            existing_resume.phone = resume_data.get('phone') or existing_resume.phone
            existing_resume.email = resume_data.get('email') or existing_resume.email
            existing_resume.education = resume_data.get('education')
            existing_resume.education_level = resume_data.get('education_level')
            existing_resume.work_years = resume_data.get('work_years', 0)
            existing_resume.skills = resume_data.get('skills', [])
            existing_resume.skills_by_level = resume_data.get('skills_by_level', {})
            existing_resume.work_experience = resume_data.get('work_experience', [])
            existing_resume.project_experience = resume_data.get('project_experience', [])
            existing_resume.education_history = resume_data.get('education_history', [])
            existing_resume.raw_text = resume_data.get('raw_text')
            existing_resume.file_path = file_path  # æ›´æ–°ä¸ºæœ€æ–°æ–‡ä»¶è·¯å¾„
            existing_resume.file_type = file_path.split('.')[-1] if '.' in file_path else None
            existing_resume.source_email_id = email_info.get('id')
            existing_resume.source_email_subject = email_info.get('subject')
            existing_resume.source_sender = email_info.get('sender')
            existing_resume.city = city
            existing_resume.candidate_cities = candidate_cities
            existing_resume.job_category = job_title
            existing_resume.pdf_path = file_path
            existing_resume.agent_score = agent_score
            existing_resume.agent_evaluation_id = agent_result.get('evaluation_id') if agent_result else None
            existing_resume.agent_evaluated_at = agent_evaluated_at
            existing_resume.screening_status = screening_status
            existing_resume.status = 'processed'

            db.commit()
            db.refresh(existing_resume)
            resume = existing_resume
        else:
            # åˆ›å»ºæ–°ç®€å†è®°å½•
            resume = Resume(
                candidate_name=resume_data.get('candidate_name'),
                phone=resume_data.get('phone'),
                email=resume_data.get('email'),
                education=resume_data.get('education'),
                education_level=resume_data.get('education_level'),
                work_years=resume_data.get('work_years', 0),
                skills=resume_data.get('skills', []),
                skills_by_level=resume_data.get('skills_by_level', {}),
                work_experience=resume_data.get('work_experience', []),
                project_experience=resume_data.get('project_experience', []),
                education_history=resume_data.get('education_history', []),
                raw_text=resume_data.get('raw_text'),
                file_path=file_path,
                file_type=file_path.split('.')[-1] if '.' in file_path else None,
                source_email_id=email_info.get('id'),
                source_email_subject=email_info.get('subject'),
                source_sender=email_info.get('sender'),
                city=city,
                candidate_cities=candidate_cities,
                job_category=job_title,
                pdf_path=file_path,
                agent_score=agent_score,
                agent_evaluation_id=agent_result.get('evaluation_id') if agent_result else None,
                agent_evaluated_at=agent_evaluated_at,
                screening_status=screening_status,
                status='processed'
            )
            db.add(resume)
            db.commit()
            db.refresh(resume)

        if needs_manual_review:
            logger.info(f"ç®€å†å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆéœ€äººå·¥å®¡æ ¸ï¼‰: {resume.id}")
        else:
            logger.info(f"ç®€å†å·²ä¿å­˜åˆ°æ•°æ®åº“: {resume.id}")

        # âŒ å·²åˆ é™¤æœ¬åœ°JobMatcherè‡ªåŠ¨åŒ¹é…ï¼ˆè¿åæ ¸å¿ƒåŸåˆ™ï¼‰

        # è¾“å‡ºå¤„ç†å®Œæˆæ—¥å¿—
        if needs_manual_review:
            logger.info(f"ç®€å†å¤„ç†å®Œæˆï¼ˆéœ€äººå·¥å®¡æ ¸ï¼‰: {resume.candidate_name}, æ— æ­£æ–‡å†…å®¹")
        elif agent_result:
            logger.info(f"ç®€å†å¤„ç†å®Œæˆ: {resume.candidate_name}, Agentè¯„åˆ†: {agent_result.get('score', 'N/A')}")

        # ä¸å†æ›´æ–°è¿›åº¦ï¼Œå› ä¸ºprocess_emailå·²ç»è®¡æ•°äº†

    except Exception as e:
        db.rollback()
        logger.error(f"å¤„ç†ç®€å†æ—¶å‡ºé”™: {e}")
        raise
    finally:
        db.close()


@celery_app.task(name='app.tasks.email_tasks.fetch_recent_resumes')
def fetch_recent_resumes(limit: int = 20):
    """æŠ“å–æœ€è¿‘Nå°é‚®ä»¶ä¸­çš„ç®€å†é™„ä»¶ï¼ˆä»è¿‘åˆ°è¿œï¼Œæ‰«ææ‰€æœ‰æ–‡ä»¶å¤¹ï¼‰

    Args:
        limit: æŠ“å–é‚®ä»¶æ•°é‡ï¼ˆé»˜è®¤20å°ï¼‰
    """
    from app.api.v1.email_monitoring import update_import_status

    logger.info(f"å¼€å§‹æŠ“å–æœ€è¿‘ {limit} å°é‚®ä»¶ä¸­çš„ç®€å†...")

    # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹æ‰«æ
    update_import_status(
        running=True,
        total=0,
        processed=0,
        current_folder="æ­£åœ¨è¿æ¥é‚®ç®±...",
        message="æ­£åœ¨æ‰«æé‚®ç®±æ–‡ä»¶å¤¹"
    )

    email_config = {
        'email_address': os.getenv('DEMO_EMAIL', 'es1@cloudpense.com'),
        'auth_code': os.getenv('DEMO_AUTH_CODE', ''),
        'imap_server': 'imap.exmail.qq.com',
        'imap_port': 993,
        'folder': 'INBOX'
    }

    if not email_config['auth_code']:
        logger.warning("æœªé…ç½®é‚®ç®±æˆæƒç ï¼Œè·³è¿‡")
        return {'status': 'error', 'message': 'æœªé…ç½®é‚®ç®±æˆæƒç '}

    # åˆ›å»ºé‚®ç®±æœåŠ¡
    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port'],
        folder=email_config['folder']
    )

    try:
        # è¿æ¥é‚®ç®±
        if not email_service.connect():
            logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
            return {'status': 'error', 'message': 'è¿æ¥é‚®ç®±å¤±è´¥'}

        # è·å–æ‰€æœ‰æ–‡ä»¶å¤¹åˆ—è¡¨
        try:
            status, folders = email_service.client.list()
            logger.info(f"IMAP list() status: {status}, è¿”å›æ•°æ®ç±»å‹: {type(folders)}, æ•°é‡: {len(folders) if folders else 0}")

            # å¯¼å…¥ IMAP UTF-7 è§£ç å™¨
            from imapclient.imap_utf7 import decode

            # å­˜å‚¨æ–‡ä»¶å¤¹ä¿¡æ¯ï¼š{decoded_name: encoded_name}
            folder_map = {}
            for line in folders:
                # line æ ¼å¼: b'(\\HasNoChildren) "/" "folder_name"'
                if isinstance(line, bytes):
                    line_str = line.decode('latin-1')
                else:
                    line_str = str(line)

                # æå–æ–‡ä»¶å¤¹åï¼ˆåœ¨æœ€åä¸€ä¸ªå¼•å·ä¸­ï¼‰
                import re
                match = re.search(r'"([^"]+)"\s*$', line_str)
                if match:
                    folder_encoded = match.group(1)
                    # è§£ç  IMAP UTF-7 (ä½¿ç”¨ imapclient çš„ decode å‡½æ•°ï¼Œéœ€è¦ bytes è¾“å…¥)
                    try:
                        folder_name_decoded = decode(folder_encoded.encode('latin-1'))
                    except:
                        folder_name_decoded = folder_encoded
                    logger.info(f"è§£ææ–‡ä»¶å¤¹: {folder_encoded} -> {folder_name_decoded}")

                    # å­˜å‚¨æ˜ å°„ï¼šdecoded -> encoded
                    folder_map[folder_name_decoded] = folder_encoded

            # è·å–æ‰€æœ‰å·²è§£ç çš„æ–‡ä»¶å¤¹ååˆ—è¡¨
            folder_names = list(folder_map.keys())
            logger.info(f"æ‰¾åˆ°æ–‡ä»¶å¤¹: {folder_names}")

            # æ‰«ææ–‡ä»¶å¤¹çš„é¡ºåºï¼šINBOXä¼˜å…ˆï¼Œç„¶åæ˜¯å…¶ä»–æ–‡ä»¶å¤¹
            folders_to_scan = []  # List of decoded names

            # å…ˆæ‰¾INBOX
            for fn in folder_names:
                if 'INBOX' in fn.upper():
                    folders_to_scan.append(fn)
                    break

            # æ·»åŠ æ‰€æœ‰å…¶ä»–æ–‡ä»¶å¤¹ï¼ˆä¸å†é™åˆ¶3ä¸ªï¼‰
            for fn in folder_names:
                if fn not in folders_to_scan:
                    # æ’é™¤ä¸€äº›ä¸éœ€è¦çš„æ–‡ä»¶å¤¹
                    if fn not in ['Drafts', 'Sent Messages', 'Deleted Messages', 'Junk']:
                        folders_to_scan.append(fn)

            logger.info(f"å°†æ‰«ææ–‡ä»¶å¤¹: {folders_to_scan}")

            # æ›´æ–°çŠ¶æ€ï¼šæ‰¾åˆ°æ–‡ä»¶å¤¹
            update_import_status(
                current_folder=f"æ‰¾åˆ° {len(folders_to_scan)} ä¸ªæ–‡ä»¶å¤¹",
                message=f"å°†æ‰«æ: {', '.join(folders_to_scan[:3])}{'...' if len(folders_to_scan) > 3 else ''}"
            )

        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤¹åˆ—è¡¨å¤±è´¥: {e}")
            update_import_status(message=f"è·å–æ–‡ä»¶å¤¹åˆ—è¡¨å¤±è´¥: {e}")
            folder_map = {'INBOX': 'INBOX'}  # Fallback mapping
            folders_to_scan = ['INBOX']

        all_emails = []
        total_found = 0

        for folder_decoded in folders_to_scan:
            logger.info(f"æ‰«ææ–‡ä»¶å¤¹: {folder_decoded}")

            # æ›´æ–°çŠ¶ï¿½ï¿½ï¼šæ­£åœ¨æ‰«ææ–‡ä»¶å¤¹
            update_import_status(
                current_folder=f"æ­£åœ¨æ‰«æ: {folder_decoded}",
                message=f"æ‰«ææ–‡ä»¶å¤¹ {len(folders_to_scan)}/{folders_to_scan.index(folder_decoded) + 1}"
            )

            # è·å–ç¼–ç åçš„æ–‡ä»¶å¤¹åï¼ˆç”¨äº IMAP æ“ä½œï¼‰
            folder_encoded = folder_map.get(folder_decoded, folder_decoded)

            # åˆ‡æ¢åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
            try:
                # ä½¿ç”¨ IMAP UTF-7 ç¼–ç çš„æ–‡ä»¶å¤¹å
                email_service.client.select(folder_encoded)
            except Exception as e:
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•å¼•ç”¨çš„æ–¹å¼
                try:
                    email_service.client.select('"{}"'.format(folder_encoded))
                except Exception as e2:
                    logger.warning(f"æ— æ³•åˆ‡æ¢åˆ°æ–‡ä»¶å¤¹ {folder_decoded} (encoded: {folder_encoded}): {e2}")
                    continue

            # è·å–è¯¥æ–‡ä»¶å¤¹çš„é‚®ä»¶
            fetch_limit = limit if limit < 1000 else 9999  # å¦‚æœlimit>=1000ï¼Œè¡¨ç¤ºè·å–å…¨éƒ¨
            emails = email_service.fetch_recent_emails(
                limit=fetch_limit,
                save_path=RESUME_SAVE_PATH  # ç›´æ¥ä¿å­˜é™„ä»¶
            )

            logger.info(f"æ–‡ä»¶å¤¹ {folder_decoded} ä¸­æ‰¾åˆ° {len(emails)} å°é‚®ä»¶")
            all_emails.extend(emails)
            total_found += len(emails)

            # æ›´æ–°çŠ¶æ€ï¼šæ‰¾åˆ°é‚®ä»¶
            update_import_status(
                total=total_found,
                message=f"åœ¨ {folder_decoded} ä¸­æ‰¾åˆ° {len(emails)} å°é‚®ä»¶"
            )

            # å¦‚æœå·²ç»æ‰¾åˆ°è¶³å¤Ÿçš„é‚®ä»¶ä¸”ä¸æ˜¯è·å–å…¨éƒ¨æ¨¡å¼ï¼Œåœæ­¢æ‰«æ
            if fetch_limit < 1000 and len(all_emails) >= fetch_limit:
                logger.info(f"å·²æ‰¾åˆ° {len(all_emails)} å°é‚®ä»¶ï¼Œè¾¾åˆ°ç›®æ ‡æ•°é‡")
                break

        # å»é‡ï¼šé€šè¿‡é‚®ä»¶ID
        seen_ids = set()
        unique_emails = []
        for email in all_emails:
            if email['id'] not in seen_ids:
                seen_ids.add(email['id'])
                unique_emails.append(email)

        logger.info(f"æ€»å…±æ‰¾åˆ° {len(unique_emails)} å°å”¯ä¸€é‚®ä»¶ï¼ˆå»é‡åï¼‰")

        # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹å¤„ç†é‚®ä»¶
        update_import_status(
            total=len(unique_emails),
            processed=0,
            current_folder="å¼€å§‹å¤„ç†é‚®ä»¶",
            message=f"æ‰¾åˆ° {len(unique_emails)} å°å¾…å¤„ç†é‚®ä»¶"
        )

        # å¤„ç†æ¯å°é‚®ä»¶ï¼ˆé™åˆ¶æ•°é‡ï¼‰
        processed_count = 0
        for idx, email_info in enumerate(unique_emails[:limit]):
            logger.info(
                f"å‡†å¤‡å¤„ç†ç¬¬ {idx+1}/{min(len(unique_emails), limit)} å°é‚®ä»¶: "
                f"{email_info['subject'][:50]}... (é™„ä»¶æ•°: {len(email_info['attachments'])})"
            )
            process_email.delay(email_info, email_config)
            processed_count += 1

            # æ¯10å°é‚®ä»¶æ›´æ–°ä¸€æ¬¡çŠ¶æ€
            if (idx + 1) % 10 == 0 or idx == len(unique_emails[:limit]) - 1:
                update_import_status(
                    processed=idx + 1,
                    message=f"å·²å¤„ç† {idx + 1}/{len(unique_emails)} å°é‚®ä»¶"
                )

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

        result = {
            'status': 'success',
            'message': f'ä» {len(folders_to_scan)} ä¸ªæ–‡ä»¶å¤¹ä¸­æ‰¾åˆ° {total_found} å°é‚®ä»¶ï¼Œå¤„ç†äº† {processed_count} å°',
            'folders_scanned': folders_to_scan,
            'total_emails_found': total_found,
            'processed': processed_count
        }

        logger.info(f"æŠ“å–å®Œæˆ: {result}")

        # æ›´æ–°çŠ¶æ€ï¼šæ‰«æå®Œæˆï¼Œç­‰å¾…åå°è§£æ
        # æ³¨æ„ï¼šrunningä¿æŒä¸ºTrueï¼Œç›´åˆ°æ‰€æœ‰è§£æä»»åŠ¡å®Œæˆ
        # è¿™é‡Œçš„messageæ”¹ä¸º"æ‰«æå®Œæˆ"ï¼Œè®©å‰ç«¯çŸ¥é“æ‰«æé˜¶æ®µå·²ç»“æŸ
        update_import_status(
            total=len(unique_emails),
            processed=processed_count,
            current_folder="æ­£åœ¨è§£æç®€å†...",
            message=f"æ‰«æå®Œæˆï¼Œ{processed_count}å°é‚®ä»¶æ­£åœ¨åå°è§£æä¸­..."
        )

        return result

    except Exception as e:
        logger.error(f"æŠ“å–é‚®ä»¶æ—¶å‡ºé”™: {e}")
        update_import_status(
            running=False,
            current_folder="å¯¼å…¥å¤±è´¥",
            message=f"æŠ“å–å¤±è´¥: {str(e)}"
        )
        return {'status': 'error', 'message': f'æŠ“å–å¤±è´¥: {str(e)}'}


@celery_app.task(name='app.tasks.email_tasks.check_new_emails')
def check_new_emails():
    """æ£€æŸ¥æ–°çš„æœªè¯»é‚®ä»¶ï¼ˆç”¨äºå®šæ—¶è‡ªåŠ¨æŠ“å–ï¼‰"""
    logger.info("å¼€å§‹æ£€æŸ¥æ–°é‚®ä»¶...")

    email_config = {
        'email_address': os.getenv('DEMO_EMAIL', 'es1@cloudpense.com'),
        'auth_code': os.getenv('DEMO_AUTH_CODE', ''),
        'imap_server': 'imap.exmail.qq.com',
        'imap_port': 993,
        'folder': 'INBOX'
    }

    if not email_config['auth_code']:
        logger.warning("æœªé…ç½®é‚®ç®±æˆæƒç ï¼Œè·³è¿‡")
        return {'status': 'error', 'message': 'æœªé…ç½®é‚®ç®±æˆæƒç '}

    # åˆ›å»ºé‚®ç®±æœåŠ¡
    email_service = EmailService(
        email_address=email_config['email_address'],
        auth_code=email_config['auth_code'],
        imap_server=email_config['imap_server'],
        imap_port=email_config['imap_port'],
        folder=email_config['folder']
    )

    try:
        # è¿æ¥é‚®ç®±
        if not email_service.connect():
            logger.error("è¿æ¥é‚®ç®±å¤±è´¥")
            return {'status': 'error', 'message': 'è¿æ¥é‚®ç®±å¤±è´¥'}

        # åªè·å–æœªè¯»é‚®ä»¶ï¼ˆä¸å†è¿‡æ»¤ï¼‰
        emails = email_service.fetch_unread_emails(
            save_path=RESUME_SAVE_PATH  # ç›´æ¥ä¿å­˜é™„ä»¶
        )

        logger.info(f"æ‰¾åˆ° {len(emails)} å°æœªè¯»é‚®ä»¶")

        if len(emails) == 0:
            logger.info("æ²¡æœ‰æ–°çš„æœªè¯»é‚®ä»¶éœ€è¦å¤„ç†")
            email_service.disconnect()
            return {
                'status': 'success',
                'message': 'æ²¡æœ‰æ–°é‚®ä»¶',
                'total_emails': 0,
                'processed': 0
            }

        # å¤„ç†æ¯å°é‚®ä»¶
        for idx, email_info in enumerate(emails):
            logger.info(
                f"å‡†å¤‡å¤„ç†ç¬¬ {idx+1}/{len(emails)} å°æ–°é‚®ä»¶: "
                f"{email_info['subject'][:50]}... (é™„ä»¶æ•°: {len(email_info['attachments'])})"
            )
            process_email.delay(email_info, email_config)

        # æ–­å¼€è¿æ¥
        email_service.disconnect()

        result = {
            'status': 'success',
            'message': f'æˆåŠŸå¤„ç† {len(emails)} å°æ–°é‚®ä»¶',
            'total_emails': len(emails),
            'processed': len(emails)
        }

        logger.info(f"æ£€æŸ¥å®Œæˆ: {result}")
        return result

    except Exception as e:
        logger.error(f"æ£€æŸ¥æ–°é‚®ä»¶æ—¶å‡ºé”™: {e}")
        return {'status': 'error', 'message': f'æ£€æŸ¥å¤±è´¥: {str(e)}'}
