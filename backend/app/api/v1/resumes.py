"""ç®€å†APIè·¯ç”±"""
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Query
from sqlalchemy.orm import Session
from typing import List, Optional
from uuid import UUID
import logging
import os
from datetime import datetime

from app.core.database import get_db
from app.models.resume import Resume
from app.models.screening_result import ScreeningResult
from app.models.job import Job
from app.services.resume_parser import ResumeParser

router = APIRouter()
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–æœåŠ¡
resume_parser = ResumeParser()

# æ–‡ä»¶ä¿å­˜ç›®å½•
UPLOAD_DIR = "/app/resume_files"
os.makedirs(UPLOAD_DIR, exist_ok=True)


@router.get("/", response_model=dict)
def list_resumes(
    skip: int = Query(0, ge=0, description="è·³è¿‡è®°å½•æ•°"),
    limit: int = Query(10, ge=1, le=500, description="è¿”å›è®°å½•æ•°"),
    status: Optional[str] = Query(None, description="ç­›é€‰çŠ¶æ€"),
    file_type: Optional[str] = Query(None, description="ç­›é€‰æ–‡ä»¶ç±»å‹"),
    has_pdf_and_content: bool = Query(False, description="åªè¿”å›æ—¢æœ‰PDFæ–‡ä»¶åˆæœ‰æ­£æ–‡çš„ï¿½ï¿½å†"),
    agent_evaluated: Optional[bool] = Query(None, description="åªè¿”å›å·²é€šè¿‡Agentè¯„ä¼°çš„ç®€å†"),
    min_score: Optional[int] = Query(None, description="æœ€ä½Agentè¯„åˆ†"),
    db: Session = Depends(get_db)
):
    """è·å–ç®€å†åˆ—è¡¨"""
    query = db.query(Resume)

    if status:
        query = query.filter(Resume.status == status)

    if file_type:
        query = query.filter(Resume.file_type == file_type)

    # åªè¿”å›æ—¢æœ‰PDFåˆæœ‰æ­£æ–‡çš„ç®€å†
    if has_pdf_and_content:
        query = query.filter(
            Resume.file_type == 'pdf',
            Resume.raw_text.isnot(None),
            Resume.raw_text != ''
        )

    # åªè¿”å›å·²é€šè¿‡Agentè¯„ä¼°çš„ç®€å†
    if agent_evaluated:
        query = query.filter(
            Resume.agent_score.isnot(None),
            Resume.agent_score > 0
        )

    # æœ€ä½Agentè¯„åˆ†
    if min_score is not None:
        query = query.filter(Resume.agent_score >= min_score)

    total = query.count()

    # æ ¹æ®æ˜¯å¦Agentè¯„ä¼°å†³å®šæ’åºæ–¹å¼
    if agent_evaluated or min_score is not None:
        resumes = query.order_by(Resume.agent_evaluated_at.desc()).offset(skip).limit(limit).all()
    else:
        resumes = query.order_by(Resume.created_at.desc()).offset(skip).limit(limit).all()

    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
    resume_list = []
    for resume in resumes:
        resume_dict = {
            "id": str(resume.id),
            "candidate_name": resume.candidate_name,
            "phone": resume.phone,
            "email": resume.email,
            "education": resume.education,
            "education_level": resume.education_level,
            "work_years": resume.work_years,
            "skills": resume.skills or [],
            "skills_by_level": resume.skills_by_level,
            "status": resume.status,
            "file_type": resume.file_type,
            "created_at": resume.created_at.isoformat() if resume.created_at else None,
            "updated_at": resume.updated_at.isoformat() if resume.updated_at else None,
            # Agentç›¸å…³å­—æ®µ
            "city": resume.city,
            "job_category": resume.job_category,
            "agent_score": resume.agent_score,
            "agent_evaluation_id": resume.agent_evaluation_id,
            "screening_status": resume.screening_status,
            "agent_evaluated_at": resume.agent_evaluated_at.isoformat() if resume.agent_evaluated_at else None,
            "work_experience": resume.work_experience  # ğŸ”´ æ–°å¢ï¼šå·¥ä½œç»å†
        }
        resume_list.append(resume_dict)

    return {
        "total": total,
        "items": resume_list,
        "page": skip // limit + 1 if limit else 1,
        "page_size": limit
    }


@router.get("/{resume_id}", response_model=dict)
def get_resume(resume_id: UUID, db: Session = Depends(get_db)):
    """è·å–ç®€å†è¯¦æƒ…"""
    resume = db.query(Resume).filter(Resume.id == resume_id).first()

    if not resume:
        raise HTTPException(status_code=404, detail="ç®€å†ä¸å­˜åœ¨")

    return {
        "id": str(resume.id),
        "candidate_name": resume.candidate_name,
        "phone": resume.phone,
        "email": resume.email,
        "education": resume.education,
        "education_level": resume.education_level,
        "work_years": resume.work_years,
        "skills": resume.skills or [],
        "skills_by_level": resume.skills_by_level,  # æ–°å¢
        "work_experience": resume.work_experience or [],
        "project_experience": resume.project_experience or [],
        "education_history": resume.education_history or [],
        "raw_text": resume.raw_text,
        "file_path": resume.file_path,
        "file_type": resume.file_type,
        "source_email_id": resume.source_email_id,
        "source_email_subject": resume.source_email_subject,
        "source_sender": resume.source_sender,
        "status": resume.status,
        "created_at": resume.created_at.isoformat() if resume.created_at else None,
        "updated_at": resume.updated_at.isoformat() if resume.updated_at else None
    }


@router.post("/upload", response_model=dict)
async def upload_resume(
    file: UploadFile = File(..., description="ç®€å†æ–‡ä»¶(PDF/DOCX)"),
    auto_match: bool = Query(True, description="æ˜¯å¦è‡ªåŠ¨åŒ¹é…å²—ä½"),
    db: Session = Depends(get_db)
):
    """æ‰‹åŠ¨ä¸Šä¼ ç®€å†å¹¶è‡ªåŠ¨åŒ¹é…

    Args:
        file: ç®€å†æ–‡ä»¶ï¼ˆPDFæˆ–DOCXï¼‰
        auto_match: æ˜¯å¦è‡ªåŠ¨åŒ¹é…æ‰€æœ‰å²—ä½
    """
    try:
        # 1. ä¿å­˜æ–‡ä»¶
        file_ext = file.filename.split('.')[-1].lower()
        if file_ext not in ['pdf', 'docx', 'doc']:
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒPDFå’ŒDOCXæ ¼å¼")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{file.filename}"
        file_path = os.path.join(UPLOAD_DIR, filename)

        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # 2. è§£æç®€å†
        logger.info(f"å¼€å§‹è§£æç®€å†: {file_path}")
        resume_data = resume_parser.parse_resume(file_path)

        # å¦‚æœä»ç„¶æ²¡æœ‰æå–åˆ°å§“åï¼Œå°è¯•ä»åŸå§‹æ–‡ä»¶åæå–
        if not resume_data.get('candidate_name'):
            candidate_name_from_filename = resume_parser._extract_name_from_filename(file.filename)
            candidate_name = candidate_name_from_filename or Path(file.filename).stem
        else:
            candidate_name = resume_data.get('candidate_name')

        # 3. ä¿å­˜åˆ°æ•°æ®åº“
        resume = Resume(
            candidate_name=candidate_name,
            phone=resume_data.get('phone'),
            email=resume_data.get('email'),
            education=resume_data.get('education'),
            work_years=resume_data.get('work_years', 0),
            skills=resume_data.get('skills', []),
            work_experience=resume_data.get('work_experience', []),
            project_experience=resume_data.get('project_experience', []),
            education_history=resume_data.get('education_history', []),
            raw_text=resume_data.get('raw_text'),
            file_path=file_path,
            file_type=file_ext,
            status='parsed'
        )

        db.add(resume)
        db.commit()
        db.refresh(resume)

        logger.info(f"ç®€å†å·²ä¿å­˜: {resume.id}, å€™é€‰äºº: {resume.candidate_name}")

        # 4. âŒ å·²åˆ é™¤æœ¬åœ°è‡ªåŠ¨åŒ¹é…åŠŸèƒ½ï¼ˆè¿åCLAUDE.mdæ ¸å¿ƒåŸåˆ™ï¼‰
        # æ ¹æ®æ ¸å¿ƒåŸåˆ™ï¼šæ‰€æœ‰è¯„åˆ†å¿…é¡»é€šè¿‡å¤–éƒ¨Agentå®Œæˆ
        # å¦‚æœéœ€è¦è‡ªåŠ¨è¯„ä¼°ï¼Œåº”è¯¥è°ƒç”¨å¤–éƒ¨AgentæœåŠ¡

        return {
            "resume_id": str(resume.id),
            "message": "ç®€å†ä¸Šä¼ æˆåŠŸï¼Œç­‰å¾…å¤–éƒ¨Agentè¯„ä¼°"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸Šä¼ ç®€å†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.delete("/{resume_id}", response_model=dict)
def delete_resume(resume_id: UUID, db: Session = Depends(get_db)):
    """åˆ é™¤ç®€å†"""
    resume = db.query(Resume).filter(Resume.id == resume_id).first()

    if not resume:
        raise HTTPException(status_code=404, detail="ç®€å†ä¸å­˜åœ¨")

    # åˆ é™¤å…³è”çš„ç­›é€‰ç»“æœ
    db.query(ScreeningResult).filter(ScreeningResult.resume_id == resume_id).delete()

    # åˆ é™¤ç®€å†æ–‡ä»¶
    if resume.file_path and os.path.exists(resume.file_path):
        try:
            os.remove(resume.file_path)
        except Exception as e:
            logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {resume.file_path}, é”™è¯¯: {str(e)}")

    # åˆ é™¤æ•°æ®åº“è®°å½•
    db.delete(resume)
    db.commit()

    return {"message": "ç®€å†å·²åˆ é™¤"}


@router.get("/{resume_id}/screenings", response_model=dict)
def get_resume_screenings(
    resume_id: UUID,
    db: Session = Depends(get_db)
):
    """è·å–ç®€å†çš„ç­›é€‰ç»“æœï¼ˆå‰2ä¸ªæœ€ä½³åŒ¹é…ï¼‰"""
    # æ£€æŸ¥ç®€å†æ˜¯å¦å­˜åœ¨
    resume = db.query(Resume).filter(Resume.id == resume_id).first()
    if not resume:
        raise HTTPException(status_code=404, detail="ç®€å†ä¸å­˜åœ¨")

    # è·å–ç­›é€‰ç»“æœï¼ŒæŒ‰åˆ†æ•°é™åºï¼Œå–å‰2ä¸ª
    screenings = db.query(ScreeningResult).filter(
        ScreeningResult.resume_id == resume_id
    ).order_by(ScreeningResult.agent_score.desc().nulls_last()).limit(2).all()

    results = []
    for screening in screenings:
        # æ‰¾åˆ°å¯¹åº”çš„å²—ä½ä¿¡æ¯ï¼ˆä»æ•°æ®åº“ï¼‰
        job = db.query(Job).filter(Job.id == screening.job_id).first()

        results.append({
            "id": str(screening.id),
            "job_id": str(screening.job_id),
            "job_name": job.name if job else "æœªçŸ¥å²—ä½",
            "job_category": job.category if job else "unknown",
            "agent_score": screening.agent_score,
            "screening_result": screening.screening_result,
            "matched_points": screening.matched_points or [],
            "unmatched_points": screening.unmatched_points or [],
            "suggestion": screening.suggestion,
            "created_at": screening.created_at.isoformat() if screening.created_at else None
        })

    return {
        "resume_id": str(resume_id),
        "candidate_name": resume.candidate_name,
        "total_matches": len(results),
        "matches": results
    }
